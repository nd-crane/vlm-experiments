{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ph3_instruct\n",
    "\n",
    "> Experiments with loading and evaluating phi-3 instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "python -m mlx_vlm.generate --model mlx-community/Phi-3-vision-128k-instruct-8bit --max-tokens 100 --temp 0.0\n",
    "\n",
    "\n",
    "## Microsoft Phi-3Cookbook\n",
    "\n",
    "- [Microsoft Phi-3 Cookbook](https://github.com/microsoft/Phi-3CookBook/blob/3f19744fe79582fd85d858895a974a70b254d472/code/09.UpdateSamples/Aug/mlx-phi35-vision.ipynb)\n",
    "- [https://medium.com/@researchgraph/what-is-phi-3-5-vision-101ce7c4d410#:~:text=One%20of%20Phi%2D3.5%2Dvision's,Character%20Recognition)%20and%20chart%20interpretation.](https://medium.com/@researchgraph/what-is-phi-3-5-vision-101ce7c4d410#:~:text=One%20of%20Phi%2D3.5%2Dvision's,Character%20Recognition)%20and%20chart%20interpretation.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp phi3_instruct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image loadin from command line\n",
    "\n",
    "```sh\n",
    "cvardema$ python -m mlx_vlm.generate --model mlx-community/Phi-3-vision-128k-instruct-8bit --max-tokens 100 --temp 0.0\n",
    "Fetching 14 files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 80881.90it/s]\n",
    "/Users/cvardema/dev/git/nd-crane/vlm-experiments/.venv/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:513: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
    "  warnings.warn(\n",
    "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n",
    "==========\n",
    "Image: http://images.cocodataset.org/val2017/000000039769.jpg \n",
    "\n",
    "Prompt: <|user|>\n",
    "<|image_1|>\n",
    "What are these?<|end|>\n",
    "<|assistant|>\n",
    "\n",
    "These are cats lying on a pink surface with remote controls.<|end|>\n",
    "==========\n",
    "Prompt: 4.995 tokens-per-sec\n",
    "Generation: 19.464 tokens-per-sec\n",
    "\n",
    "```\n",
    "\n",
    "![Test Image](./img/000000039769.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe931ed872694152ac107e224ad2322c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 14 files:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "amimport mlx.core as mx\n",
    "from mlx_vlm import load, generate\n",
    "model_path = \"mlx-community/Phi-3-vision-128k-instruct-8bit\"\n",
    "model, processor = load(model_path,processor_config={\"trust_remote_code\":\"True\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests, base64\n",
    "\n",
    "image = Image.open(\"./img/000000039769.jpg\")\n",
    "placeholder = f\"<|image_1|>\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = processor.tokenizer.apply_chat_template(\n",
    "    [{\"role\": \"user\", \"content\": f\"<image>\\nWhat are these?\"}],\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'These are cats lying on a pink surface with remotes beside them.<|end|>'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = generate(model, processor, image, placeholder+prompt, verbose=False)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "                {\"role\": \"user\", \"content\": \"Summarize the video.\"}, \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = processor.tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = generate(model, processor, images, placeholder+prompt, verbose=False, max_tokens=1024)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document processing\n",
    "\n",
    "### FAA Authorized Release Certificate\n",
    "![](./img/authorized_release_certificate.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt for Document Analysis\n",
    "\n",
    "# Analyze document page\n",
    "\n",
    "```python\n",
    "document_prompt = \"\"\"\n",
    "<|image_1|>\n",
    "This image is a page from a scientific paper. Please analyze the content of this page, including:\n",
    "1. The title of the paper (if visible)\n",
    "2. Section headers\n",
    "3. Key points or findings mentioned in the text\n",
    "4. Any references to figures or charts\n",
    "5. Any visible citations or references\n",
    "\n",
    "Please be as detailed as possible in your analysis.\n",
    "\"\"\"\n",
    "\n",
    "document_conversation = [\n",
    "    {\"role\": \"user\", \"content\": document_prompt}\n",
    "]\n",
    "\n",
    "document_response = generate_response(document_conversation, [document_page])\n",
    "document_conversation.append({\"role\": \"assistant\", \"content\": document_response})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"./img/authorized_release_certificate.png\")\n",
    "placeholder = f\"<|image_1|>\\n\"\n",
    "\n",
    "prompt = processor.tokenizer.apply_chat_template(\n",
    "    [{\"role\": \"user\", \"content\": f\"<image>\\nWhat conceptual entities are contained in this document?\"}],\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The document contains the conceptual entities of 'Approving Civil Aviation', 'FAA Form 8130-3', 'AIRWOR', 'FAA Form 8130-3 (02-140)', and 'User/Installer Responsibilities'.<|end|>\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = generate(model, processor, image, placeholder+prompt, verbose=False)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
